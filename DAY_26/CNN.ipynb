{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e9d479-0893-4a01-a10c-29d3674fbc20",
   "metadata": {},
   "source": [
    "# What is CNN?\n",
    "- cnn are sepical neural networks for img\n",
    "- they learn to detect patterns like\n",
    "1. edges,shapes\n",
    "2. texteus,objects\n",
    "3. insteted of feding of row img pixcels to a normaql ANN CNN uses filters (kernels) that slide over the img and extract features just like your eyes scaning an object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0350c3-c8e1-49b5-ac81-d578da38aa33",
   "metadata": {},
   "source": [
    "# input image\n",
    "    ↓\n",
    "convoluction  → "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798bdc9-ae65-41ff-aa21-e0a8c27a9b82",
   "metadata": {},
   "source": [
    "# dataset =  mnist (28*28 img of digits) 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbbc3b4-ef4c-4a8d-bb75-94b9c1f0f8dd",
   "metadata": {},
   "source": [
    "- Each img is 28*28 pixel\n",
    "- grays scale\n",
    "- labeled with the correct digit (0 to 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf97e0f-b722-47ff-8656-8ed9cfbcd403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e8215d-22b6-49ec-9d47-c4ae4f2b349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (60000, 28, 28, 1)\n",
      "test shape (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
    "\n",
    "# reshape for CNN :(samples,height , width , channel)\n",
    "X_train = X_train.reshape(-1,28,28,1).astype('float32')/255\n",
    "X_test = X_test.reshape(-1,28,28,1).astype('float32')/255\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(\"train shape\",X_train.shape)\n",
    "print(\"test shape\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98204fbf-4502-4804-8b67-b5226466b67f",
   "metadata": {},
   "source": [
    "# Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432d5e69-44e0-40d2-b83a-680d1d8008c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape = (28,28,1)))\n",
    "\n",
    "# Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Flatten before Dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connect layer \n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "\n",
    "# output layer (10 digits)\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8593d74d-7346-45a8-a57d-83fb814ea1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model.\n",
    "model.compile(optimizer='Adam',loss = 'categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e75865d4-c5fe-45ef-b399-9cb5a86bd6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 37ms/step - accuracy: 0.9593 - loss: 0.1334 - val_accuracy: 0.9841 - val_loss: 0.0477\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 38ms/step - accuracy: 0.9863 - loss: 0.0428 - val_accuracy: 0.9881 - val_loss: 0.0321\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.9910 - loss: 0.0287 - val_accuracy: 0.9915 - val_loss: 0.0279\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 38ms/step - accuracy: 0.9931 - loss: 0.0215 - val_accuracy: 0.9889 - val_loss: 0.0318\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 35ms/step - accuracy: 0.9947 - loss: 0.0157 - val_accuracy: 0.9905 - val_loss: 0.0304\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.9958 - loss: 0.0124 - val_accuracy: 0.9885 - val_loss: 0.0370\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 37ms/step - accuracy: 0.9970 - loss: 0.0093 - val_accuracy: 0.9898 - val_loss: 0.0368\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 45ms/step - accuracy: 0.9972 - loss: 0.0080 - val_accuracy: 0.9902 - val_loss: 0.0364\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 45ms/step - accuracy: 0.9976 - loss: 0.0072 - val_accuracy: 0.9916 - val_loss: 0.0342\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 47ms/step - accuracy: 0.9980 - loss: 0.0061 - val_accuracy: 0.9902 - val_loss: 0.0424\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs = 10, batch_size= 32,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec02f5f9-ac2a-43eb-8584-ec8e445d0d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
